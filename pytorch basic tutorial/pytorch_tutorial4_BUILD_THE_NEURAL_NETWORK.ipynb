{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_tutorial4_BUILD THE NEURAL NETWORK.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S0DYV1GFcT1Y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Device for Training"
      ],
      "metadata": {
        "id": "BsUAs4VychOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "id": "mNou8Wzachuj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "782c07e2-3e94-4b4a-cd73-803579667322"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the Class"
      ],
      "metadata": {
        "id": "k-mpafhmePm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "xOcfMTYweP56"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ciy8awI0eQAg",
        "outputId": "56d7eae5-9048-4abb-8d92-39ff52920736"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(1, 28, 28, device=device)\n",
        "logits = model(X)\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Rb81ic5gGuL",
        "outputId": "05a1d7b2-a268-4e5c-fd0a-7e103755b88b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([1], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Layers"
      ],
      "metadata": {
        "id": "KoMjxYR6gZjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_image = torch.rand(3,28,28)\n",
        "print(input_image.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JF7nG40SgbUR",
        "outputId": "f0a5d5fa-7720-4de6-9ed6-da397c6e1205"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flatten = nn.Flatten()\n",
        "flat_image = flatten(input_image)\n",
        "print(flat_image.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_-fpt02gbZw",
        "outputId": "bb4467ce-0b7b-4d55-f0b5-c69dba0ab53a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
        "hidden1 = layer1(flat_image)\n",
        "print(hidden1.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrK77wGbhCzy",
        "outputId": "9aa3c24a-9988-4c9a-8936-84e5c8934f1a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
        "hidden1 = nn.ReLU()(hidden1)\n",
        "print(f\"After ReLU: {hidden1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQ8foEzHhVlx",
        "outputId": "e5f71095-5a6d-4d97-f5fe-4aba946e9991"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before ReLU: tensor([[ 0.3009,  0.0086,  0.1127,  0.4688, -0.0959, -0.1043,  0.4505,  0.2544,\n",
            "         -0.2083,  0.3243, -0.5553, -0.1969, -0.7053, -0.2156,  0.4449,  0.0561,\n",
            "         -0.1545,  0.2885, -0.6607,  0.3888],\n",
            "        [-0.0033,  0.0350,  0.0760,  0.3630, -0.0178, -0.0238,  0.4613,  0.2113,\n",
            "         -0.0213, -0.1628, -0.4584, -0.4208, -0.3913,  0.0992,  0.2705,  0.1325,\n",
            "         -0.0999,  0.2474, -0.5089,  0.4425],\n",
            "        [ 0.1671, -0.0310, -0.1954,  0.4566, -0.3884, -0.1160, -0.1456,  0.1157,\n",
            "         -0.3491,  0.1840, -0.6424, -0.3810, -0.5095, -0.1667,  0.4019,  0.0233,\n",
            "         -0.2413,  0.3123, -0.5963,  0.2831]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "\n",
            "After ReLU: tensor([[0.3009, 0.0086, 0.1127, 0.4688, 0.0000, 0.0000, 0.4505, 0.2544, 0.0000,\n",
            "         0.3243, 0.0000, 0.0000, 0.0000, 0.0000, 0.4449, 0.0561, 0.0000, 0.2885,\n",
            "         0.0000, 0.3888],\n",
            "        [0.0000, 0.0350, 0.0760, 0.3630, 0.0000, 0.0000, 0.4613, 0.2113, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0992, 0.2705, 0.1325, 0.0000, 0.2474,\n",
            "         0.0000, 0.4425],\n",
            "        [0.1671, 0.0000, 0.0000, 0.4566, 0.0000, 0.0000, 0.0000, 0.1157, 0.0000,\n",
            "         0.1840, 0.0000, 0.0000, 0.0000, 0.0000, 0.4019, 0.0233, 0.0000, 0.3123,\n",
            "         0.0000, 0.2831]], grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_modules = nn.Sequential(\n",
        "    flatten,\n",
        "    layer1,\n",
        "    nn.ReLU(),\n",
        "     nn.Linear(20, 10)\n",
        ")\n",
        "input_image = torch.rand(3,28,28)\n",
        "logits = seq_modules(input_image)\n",
        "print(logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTDlrQTshgKy",
        "outputId": "bf80f1f7-df2d-41ad-d48c-ece3fd2b0637"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1114, -0.1453,  0.0957,  0.1203,  0.0374, -0.0425, -0.0158, -0.1851,\n",
            "         -0.0660,  0.0771],\n",
            "        [-0.1545, -0.2087,  0.1245,  0.2947, -0.0583, -0.0415, -0.1425, -0.1805,\n",
            "          0.0234,  0.1470],\n",
            "        [ 0.0099, -0.0482,  0.0937,  0.1783,  0.0196, -0.0613, -0.1130,  0.0247,\n",
            "         -0.0222,  0.1801]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "softmax = nn.Softmax(dim=1)\n",
        "pred_probab = softmax(logits)\n",
        "print(pred_probab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0RUilxoiNmL",
        "outputId": "31c13782-2332-4cd1-bac7-9ecf6baea638"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0911, 0.0881, 0.1121, 0.1149, 0.1058, 0.0976, 0.1003, 0.0847, 0.0954,\n",
            "         0.1100],\n",
            "        [0.0863, 0.0817, 0.1141, 0.1352, 0.0950, 0.0966, 0.0873, 0.0841, 0.1031,\n",
            "         0.1166],\n",
            "        [0.0980, 0.0924, 0.1065, 0.1159, 0.0989, 0.0912, 0.0866, 0.0994, 0.0949,\n",
            "         0.1161]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Parameters"
      ],
      "metadata": {
        "id": "meaT0FwCikpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model structure: {model}\\n\\n\")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWSDiDOQilz6",
        "outputId": "f4a2f483-326d-4fb8-8f79-bedf7dc7c2c7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model structure: NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "\n",
            "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 1.5211e-02,  7.2309e-05,  2.7034e-02,  ..., -8.1781e-03,\n",
            "         -2.2732e-02, -3.0738e-02],\n",
            "        [ 2.4532e-02,  7.1489e-03, -7.4539e-03,  ...,  7.8258e-03,\n",
            "          3.0587e-02,  1.1749e-02]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0026, -0.0188], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0360, -0.0035,  0.0424,  ..., -0.0053,  0.0050, -0.0403],\n",
            "        [-0.0043,  0.0296,  0.0370,  ..., -0.0171, -0.0353,  0.0153]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0237,  0.0441], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0286, -0.0250, -0.0396,  ...,  0.0353,  0.0245,  0.0118],\n",
            "        [-0.0315, -0.0141, -0.0080,  ..., -0.0299, -0.0192, -0.0022]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0289,  0.0424], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n"
          ]
        }
      ]
    }
  ]
}